{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postgres Memory Store:\n",
    "\n",
    "1. Intsall docker\n",
    "2. Run docker --version\n",
    "3. docker run --name langgraph-postgres \\\n",
    "    -e POSTGRES_USER-postgres \\\n",
    "    -e POSTGRES_PASSWORD-postgres \\\n",
    "    -e POSTGRES_DB=postgres \\\n",
    "    -p 5442:5432 \\\n",
    "    -d postgres:16\n",
    "4. Run docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/rishukumar/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/bin/pip: cannot execute: required file not found\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"psycopg[binary,pool]\" langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishukumar/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769798410.925273   10039 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2) System prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 3 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# 3) Memory extraction LLM\n",
    "# ----------------------------\n",
    "memory_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")\n",
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)\n",
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769798410.995398   10039 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3) Nodes\n",
    "# ----------------------------\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # existing memory (all items under namespace)\n",
    "    items = store.search(ns)\n",
    "    existing = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"(empty)\"\n",
    "\n",
    "    # latest user message\n",
    "    last_text = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=existing)),\n",
    "            {\"role\": \"user\", \"content\": last_text},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "\n",
    "    return {}\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fdafcded210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    user_details = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT_TEMPLATE.format(user_details_content=user_details or \"(empty)\")\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "# ----------------------------\n",
    "# 4) Build graph\n",
    "# ----------------------------\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nMultiple connection attempts failed. All failures were:\n- host: 'localhost', port: '5442', hostaddr: '::1': connection failed: connection to server at \"::1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n- host: 'localhost', port: '5442', hostaddr: '127.0.0.1': connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 5) Use PostgresStore (PERSISTENT LTM)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m      4\u001b[39m DB_URI = \u001b[33m\"\u001b[39m\u001b[33mpostgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPostgresStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_conn_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDB_URI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# IMPORTANT: run ONCE the first time you use this database\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/lib64/python3.11/site-packages/langgraph/store/postgres/base.py:795\u001b[39m, in \u001b[36mPostgresStore.from_conn_string\u001b[39m\u001b[34m(cls, conn_string, pipeline, pool_config, index, ttl)\u001b[39m\n\u001b[32m    793\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(conn=pool, index=index, ttl=ttl)\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_row\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline:\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m conn.pipeline() \u001b[38;5;28;01mas\u001b[39;00m pipe:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/lib64/python3.11/site-packages/psycopg/connection.py:129\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m     lines.append(\u001b[33m\"\u001b[39m\u001b[33mMultiple connection attempts failed. All failures were:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    128\u001b[39m     lines.extend((\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m error, descr \u001b[38;5;129;01min\u001b[39;00m conn_errors))\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(last_ex)(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(lines)).with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    132\u001b[39m     capabilities.has_used_gssapi()\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m rv.pgconn.used_gssapi\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m gssapi_requested(params))\n\u001b[32m    135\u001b[39m ):\n\u001b[32m    136\u001b[39m     warnings.warn(\n\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe connection was obtained using the GSSAPI relying on the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgssencmode=prefer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m libpq default. The value for this default might be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead, in certain psycopg[binary] implementations. If you wish to interact with the GSSAPI reliably please set the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgssencmode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter in the connection string or the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPGGSSENCMODE\u001b[39m\u001b[33m'\u001b[39m\u001b[33m environment variable to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprefer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrequire\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    138\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[32m    139\u001b[39m     )\n",
      "\u001b[31mOperationalError\u001b[39m: connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nMultiple connection attempts failed. All failures were:\n- host: 'localhost', port: '5442', hostaddr: '::1': connection failed: connection to server at \"::1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n- host: 'localhost', port: '5442', hostaddr: '127.0.0.1': connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Use PostgresStore (PERSISTENT LTM)\n",
    "# ----------------------------\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    # IMPORTANT: run ONCE the first time you use this database\n",
    "    store.setup()\n",
    "\n",
    "    graph = builder.compile(store=store)\n",
    "\n",
    "    config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Nitish\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I teach AI on YouTube\"}]}, config)\n",
    "\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Explain GenAI simply\"}]}, config)\n",
    "    print(out[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n--- Stored Memories (from Postgres) ---\")\n",
    "    for it in store.search((\"user\", \"u1\", \"details\")):\n",
    "        print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nMultiple connection attempts failed. All failures were:\n- host: 'localhost', port: '5442', hostaddr: '::1': connection failed: connection to server at \"::1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n- host: 'localhost', port: '5442', hostaddr: '127.0.0.1': connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostgres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PostgresStore\n\u001b[32m      3\u001b[39m DB_URI = \u001b[33m\"\u001b[39m\u001b[33mpostgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPostgresStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_conn_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDB_URI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mns\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mu1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdetails\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/lib64/python3.11/site-packages/langgraph/store/postgres/base.py:795\u001b[39m, in \u001b[36mPostgresStore.from_conn_string\u001b[39m\u001b[34m(cls, conn_string, pipeline, pool_config, index, ttl)\u001b[39m\n\u001b[32m    793\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(conn=pool, index=index, ttl=ttl)\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_row\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline:\n\u001b[32m    799\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m conn.pipeline() \u001b[38;5;28;01mas\u001b[39;00m pipe:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CampusX/CampusX_Code/LangGraph_CampusX/myenv/lib64/python3.11/site-packages/psycopg/connection.py:129\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m     lines.append(\u001b[33m\"\u001b[39m\u001b[33mMultiple connection attempts failed. All failures were:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    128\u001b[39m     lines.extend((\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m error, descr \u001b[38;5;129;01min\u001b[39;00m conn_errors))\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(last_ex)(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(lines)).with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    132\u001b[39m     capabilities.has_used_gssapi()\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m rv.pgconn.used_gssapi\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m gssapi_requested(params))\n\u001b[32m    135\u001b[39m ):\n\u001b[32m    136\u001b[39m     warnings.warn(\n\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe connection was obtained using the GSSAPI relying on the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgssencmode=prefer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m libpq default. The value for this default might be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead, in certain psycopg[binary] implementations. If you wish to interact with the GSSAPI reliably please set the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgssencmode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter in the connection string or the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPGGSSENCMODE\u001b[39m\u001b[33m'\u001b[39m\u001b[33m environment variable to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprefer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrequire\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    138\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[32m    139\u001b[39m     )\n",
      "\u001b[31mOperationalError\u001b[39m: connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nMultiple connection attempts failed. All failures were:\n- host: 'localhost', port: '5442', hostaddr: '::1': connection failed: connection to server at \"::1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n- host: 'localhost', port: '5442', hostaddr: '127.0.0.1': connection failed: connection to server at \"127.0.0.1\", port 5442 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?"
     ]
    }
   ],
   "source": [
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    ns = (\"user\", \"u1\", \"details\")\n",
    "    items = store.search(ns)\n",
    "\n",
    "for it in items:\n",
    "    print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
