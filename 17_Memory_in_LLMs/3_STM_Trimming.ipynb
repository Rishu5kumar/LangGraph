{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages.utils import trim_messages,count_tokens_approximately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767807608.935130    5613 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    \n",
    "    # Trim conversation history -> last N messages that fit within the token budget\n",
    "    messages = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",                      \n",
    "        token_counter=count_tokens_approximately, # to count tokens\n",
    "        max_tokens=MAX_TOKENS\n",
    "    )\n",
    "\n",
    "    print('Current Token Count ->', count_tokens_approximately(messages=messages))\n",
    "\n",
    "    for message in messages:\n",
    "        print(message.content)\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fba0477e010>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7fba0477eb50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 10\n",
      "Hi, my name is Rishu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Rishu! It's nice to meet you.\\n\\nHow can I help you today?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"chat-1\"}}\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Rishu.\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 41\n",
      "Hi, my name is Rishu.\n",
      "Hello Rishu! It's nice to meet you.\n",
      "\n",
      "How can I help you today?\n",
      "I am learning LangGraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's fantastic, Rishu! LangGraph is a powerful and incredibly useful library for building robust, stateful multi-actor applications and agents with LLMs. It's a great choice for creating complex, interactive AI systems.\\n\\nWhat stage are you at in your learning journey? Are you:\\n\\n*   Just getting started with the core concepts (nodes, edges, state)?\\n*   Exploring specific features like cycles, memory, or human-in-the-loop?\\n*   Working on a particular project or example?\\n*   Running into any specific challenges or questions?\\n\\nI'd be happy to help with explanations, code examples, debugging, or pointing you to useful resources!\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I am learning LangGraph.\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 13\n",
      "Can you explain short term memory?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Short-term memory (STM) is a temporary storage system that holds a limited amount of information for a brief period, allowing us to actively process and use it in the present moment. Think of it as your brain\\'s mental \"scratchpad\" or \"RAM.\"\\n\\nHere\\'s a breakdown of its key characteristics:\\n\\n1.  **Limited Duration:**\\n    *   Information in STM typically lasts for only about **15 to 30 seconds** if it\\'s not actively rehearsed or attended to.\\n    *   Without conscious effort (like repeating a number to yourself), the information quickly fades or is replaced by new incoming information.\\n\\n2.  **Limited Capacity:**\\n    *   STM can only hold a small amount of information at any given time.\\n    *   A classic finding by psychologist George A. Miller (1956) suggested its capacity is roughly **\"7 plus or minus 2\" items or \"chunks\"** of information.\\n    *   **Chunking** is a strategy where you group discrete pieces of information into larger, more meaningful units. For example, remembering \"1-9-4-5\" (four digits) is easier than remembering \"1-9-4-5-6-7-8-9\" (eight digits), but if you chunk \"1945\" as \"the year the war ended,\" it counts as one chunk, effectively expanding your STM capacity.\\n\\n3.  **Active and Conscious:**\\n    *   The information in STM is what you are currently aware of and actively thinking about.\\n    *   It\\'s the \"working space\" where your mind processes new sensory input, retrieves information from long-term memory, and integrates them.\\n\\n4.  **Vulnerable to Interference:**\\n    *   Because of its limited capacity and duration, STM is highly susceptible to interference. New information can easily displace old information before it has a chance to be consolidated into long-term memory.\\n\\n---\\n\\n**Short-Term Memory vs. Working Memory:**\\n\\nIt\\'s important to note that while \"short-term memory\" is often used interchangeably with \"working memory,\" there\\'s a subtle but significant distinction in cognitive psychology:\\n\\n*   **Short-Term Memory (STM):** Traditionally viewed as a **passive storage component** – simply holding information for a brief period.\\n*   **Working Memory (WM):** A more modern and comprehensive concept. It **includes the storage aspect of STM but also adds the active manipulation and processing** of that information. Working memory is what allows you to not just *remember* a phone number, but also *rearrange* it, *repeat* it backward, or *use* it to solve a problem. It\\'s the system responsible for planning, reasoning, and problem-solving.\\n\\nMost psychologists today use \"working memory\" to describe the active, dynamic system that allows us to hold and manipulate information for immediate tasks, acknowledging that it encompasses the core functions previously attributed solely to short-term memory.\\n\\n---\\n\\n**Examples of Short-Term Memory in action:**\\n\\n*   **Remembering a phone number** someone just told you long enough to dial it.\\n*   **Following a conversation**, remembering the beginning of a sentence as you hear the end.\\n*   **Looking up directions** and holding them in your mind as you drive a short distance.\\n*   **Calculating a tip** in your head, holding the bill total and the percentage in mind simultaneously.\\n\\nIn essence, short-term memory (or working memory) is crucial for our moment-to-moment functioning, allowing us to interact with the world, understand language, and solve immediate problems.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Can you explain short term memory?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 8\n",
      "What is my name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 57.08096809s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 54.663826506s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 54\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 50.249075227s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. As an AI, I don't have access to personal information about you.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Rishu.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Hello Rishu! It's nice to meet you.\n",
      "\n",
      "How can I help you today?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "I am learning LangGraph.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "That's fantastic, Rishu! LangGraph is a powerful and incredibly useful library for building robust, stateful multi-actor applications and agents with LLMs. It's a great choice for creating complex, interactive AI systems.\n",
      "\n",
      "What stage are you at in your learning journey? Are you:\n",
      "\n",
      "*   Just getting started with the core concepts (nodes, edges, state)?\n",
      "*   Exploring specific features like cycles, memory, or human-in-the-loop?\n",
      "*   Working on a particular project or example?\n",
      "*   Running into any specific challenges or questions?\n",
      "\n",
      "I'd be happy to help with explanations, code examples, debugging, or pointing you to useful resources!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Can you explain short term memory?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Short-term memory (STM) is a temporary storage system that holds a limited amount of information for a brief period, allowing us to actively process and use it in the present moment. Think of it as your brain's mental \"scratchpad\" or \"RAM.\"\n",
      "\n",
      "Here's a breakdown of its key characteristics:\n",
      "\n",
      "1.  **Limited Duration:**\n",
      "    *   Information in STM typically lasts for only about **15 to 30 seconds** if it's not actively rehearsed or attended to.\n",
      "    *   Without conscious effort (like repeating a number to yourself), the information quickly fades or is replaced by new incoming information.\n",
      "\n",
      "2.  **Limited Capacity:**\n",
      "    *   STM can only hold a small amount of information at any given time.\n",
      "    *   A classic finding by psychologist George A. Miller (1956) suggested its capacity is roughly **\"7 plus or minus 2\" items or \"chunks\"** of information.\n",
      "    *   **Chunking** is a strategy where you group discrete pieces of information into larger, more meaningful units. For example, remembering \"1-9-4-5\" (four digits) is easier than remembering \"1-9-4-5-6-7-8-9\" (eight digits), but if you chunk \"1945\" as \"the year the war ended,\" it counts as one chunk, effectively expanding your STM capacity.\n",
      "\n",
      "3.  **Active and Conscious:**\n",
      "    *   The information in STM is what you are currently aware of and actively thinking about.\n",
      "    *   It's the \"working space\" where your mind processes new sensory input, retrieves information from long-term memory, and integrates them.\n",
      "\n",
      "4.  **Vulnerable to Interference:**\n",
      "    *   Because of its limited capacity and duration, STM is highly susceptible to interference. New information can easily displace old information before it has a chance to be consolidated into long-term memory.\n",
      "\n",
      "---\n",
      "\n",
      "**Short-Term Memory vs. Working Memory:**\n",
      "\n",
      "It's important to note that while \"short-term memory\" is often used interchangeably with \"working memory,\" there's a subtle but significant distinction in cognitive psychology:\n",
      "\n",
      "*   **Short-Term Memory (STM):** Traditionally viewed as a **passive storage component** – simply holding information for a brief period.\n",
      "*   **Working Memory (WM):** A more modern and comprehensive concept. It **includes the storage aspect of STM but also adds the active manipulation and processing** of that information. Working memory is what allows you to not just *remember* a phone number, but also *rearrange* it, *repeat* it backward, or *use* it to solve a problem. It's the system responsible for planning, reasoning, and problem-solving.\n",
      "\n",
      "Most psychologists today use \"working memory\" to describe the active, dynamic system that allows us to hold and manipulate information for immediate tasks, acknowledging that it encompasses the core functions previously attributed solely to short-term memory.\n",
      "\n",
      "---\n",
      "\n",
      "**Examples of Short-Term Memory in action:**\n",
      "\n",
      "*   **Remembering a phone number** someone just told you long enough to dial it.\n",
      "*   **Following a conversation**, remembering the beginning of a sentence as you hear the end.\n",
      "*   **Looking up directions** and holding them in your mind as you drive a short distance.\n",
      "*   **Calculating a tip** in your head, holding the bill total and the percentage in mind simultaneously.\n",
      "\n",
      "In essence, short-term memory (or working memory) is crucial for our moment-to-moment functioning, allowing us to interact with the world, understand language, and solve immediate problems.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "What is my name?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "I don't know your name. As an AI, I don't have access to personal information about you.\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for item in graph.get_state({\"configurable\": {\"thread_id\": \"chat-1\"}}).values['messages']:\n",
    "    print(item.content)\n",
    "    print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
